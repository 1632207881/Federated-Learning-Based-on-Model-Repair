{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "from clientBase import clientBase\n",
    "from serverBase import serverBase\n",
    "from models     import CNN,  BaseHeadSplit\n",
    "from readData   import read_client_data_text, read_client_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FedMR(serverBase):\n",
    "    def __init__(self, args, times):\n",
    "        super().__init__(args, times)\n",
    "        self.aggregate_weights = []\n",
    "        self.set_clients(args, clientMR)\n",
    "        \n",
    "        self.Budget = []\n",
    "        \n",
    "        self.accs = [[] for _ in range(self.num_clients)]\n",
    "        self.repaired_head = None\n",
    "        \n",
    "    def train(self):\n",
    "        for i in range(self.global_rounds+1):\n",
    "            s_t = time.time()\n",
    "            self.selected_clients = self.select_clients()\n",
    "            self.send_models()\n",
    "            \n",
    "            # Ensure that the client executes only after receiving the latest global model.\n",
    "            if i > 10 :\n",
    "                self.aggregate_revised_head(i)\n",
    "            \n",
    "            if i % self.eval_gap == 0:\n",
    "                print(f\"\\n-------------Round number: {i}-------------\")\n",
    "                print(\"\\nEvaluate global model\")\n",
    "                self.evaluate()\n",
    "            \n",
    "            for client in self.selected_clients: \n",
    "                client.train(i)\n",
    "            \n",
    "            self.receive_models()\n",
    "            self.aggregate_parameters()\n",
    "            \n",
    "            self.Budget.append(time.time() - s_t)\n",
    "            print('-'*50, self.Budget[-1])\n",
    "            \n",
    "        print(\"aggregated_var\", self.aggregated_var)\n",
    "        print(\"balanced_var\", self.balanced_var)\n",
    "\n",
    "        print(\"\\nBest global accuracy.\")\n",
    "        print(max(self.rs_test_acc))\n",
    "        print(sum(self.Budget[1:])/len(self.Budget[1:]))\n",
    "        \n",
    "        print(f\"acc:  {self.rs_test_acc}\")\n",
    "        print(f\"loss: {self.rs_train_loss}\")\n",
    "\n",
    "    def set_clients(self, args, clientObj):\n",
    "        for i in range(self.num_clients):\n",
    "            if args.task == \"NLP\":\n",
    "                train_data = read_client_data_text(self.dataset, i, is_train=True)\n",
    "                test_data  = read_client_data_text(self.dataset, i, is_train=False)\n",
    "            else:\n",
    "                train_data = read_client_data(self.dataset, i, is_train=True)\n",
    "                test_data  = read_client_data(self.dataset, i, is_train=False)\n",
    "\n",
    "            client = clientObj(args, \n",
    "                            id=i, \n",
    "                            train_samples=len(train_data), \n",
    "                            test_samples=len(test_data))\n",
    "            self.clients.append(client)\n",
    "            self.aggregate_weights.append(((client.client_classes * 1.0) / client.num_classes) * client.train_samples)\n",
    "\n",
    "    \n",
    "    # Collect and aggregate the repaired heads.\n",
    "    def aggregate_revised_head(self, r):\n",
    "        uploaded_revised_heads = []\n",
    "        # Select the clients that need to be uploaded.\n",
    "        selected_ids = [self.clients.index(client)  for client in self.selected_clients]\n",
    "        selected_weights = [self.aggregate_weights[i] for i in selected_ids]\n",
    "        selected_weights = torch.tensor(selected_weights)\n",
    "        selected_weights, top_k_indices = torch.topk(selected_weights, k=4)\n",
    "        selected_clients = [self.selected_clients[i] for i in top_k_indices]\n",
    "        # Collect\n",
    "        for client in selected_clients:\n",
    "            revised_haeds = client.get_local_repaired_head(flag=True)\n",
    "            uploaded_revised_heads.append(revised_haeds)\n",
    "        \n",
    "        selected_weights = selected_weights / torch.sum(selected_weights)\n",
    "        \n",
    "        # Aggregate\n",
    "        self.repaired_head = copy.deepcopy(uploaded_revised_heads[0])\n",
    "        for param in self.repaired_head.parameters():\n",
    "            param.data.zero_()\n",
    "        for local_head, w in zip(uploaded_revised_heads, selected_weights):\n",
    "            for global_param, local_param in zip(self.repaired_head.parameters(), local_head.parameters()):\n",
    "                global_param.data += local_param.data.clone() * w\n",
    "        \n",
    "        #  Send to all clients, but only use their test sets to evaluate performance.\n",
    "        #  The unselected clients will not be optimized in this round, nor will their models be collected.\n",
    "        for client in self.clients:\n",
    "            client.set_local_repaired_head(self.repaired_head)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_repeat(data, labels, batch_size=10):\n",
    "    # Resample to expand to at least one batch size.\n",
    "    dims = data.shape\n",
    "    repeats = (batch_size + dims[0] - 1) // dims[0]\n",
    "    if repeats == 1:\n",
    "        return data, labels\n",
    "    else:\n",
    "        if len(dims) == 4:\n",
    "            expanded_data = data.repeat(repeats, 1, 1, 1)\n",
    "        elif len(dims) == 3:\n",
    "            expanded_data = data.repeat(repeats, 1, 1)\n",
    "        elif len(dims) == 2:\n",
    "            expanded_data = data.repeat(repeats, 1)\n",
    "        expanded_labels = labels.repeat(repeats)\n",
    "        \n",
    "        return expanded_data, expanded_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class clientMR(clientBase):\n",
    "    def __init__(self, args, id, train_samples, test_samples):\n",
    "        super().__init__(args, id, train_samples, test_samples)\n",
    "        \n",
    "        # Settings related to the FedMR algorithm.\n",
    "        trainloader = self.load_train_data(batch_size=1)\n",
    "        for x, y in trainloader:\n",
    "            if type(x) == type([]):\n",
    "                x[0] = x[0].to(self.device)\n",
    "            else:\n",
    "                x = x.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                rep = self.model.base(x).detach()\n",
    "            break\n",
    "        self.feature_shape = torch.zeros_like(rep.squeeze())\n",
    "        \n",
    "        self.sample_per_class = torch.zeros(self.num_classes).to(self.device)\n",
    "        for x, y in trainloader:\n",
    "            for yy in y:\n",
    "                self.sample_per_class[yy.item()] += 1\n",
    "        self.client_classes = torch.count_nonzero(self.sample_per_class).item()\n",
    "        \n",
    "        self.ft_learning_rate = args.ft_learning_rate\n",
    "        self.repaired_head = None\n",
    "        self.revise_steps = args.revise_steps\n",
    "        self.revise_weights = None\n",
    "        self.mu = args.mu\n",
    "        self.lamda = 1.0\n",
    "        self.prototypes = None\n",
    "\n",
    "    def train(self, r):\n",
    "        print(f\"[Client: {self.id:3d}] train.\")\n",
    "        trainloader = self.load_train_data()\n",
    "        self.model.train()\n",
    "\n",
    "        for step in range(self.local_steps):\n",
    "            for i, (x, y) in enumerate(trainloader):\n",
    "                if type(x) == type([]):\n",
    "                    x[0] = x[0].to(self.device)\n",
    "                else:\n",
    "                    x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                \n",
    "                output = self.model(x)\n",
    "                loss = self.loss(output, y)\n",
    "\n",
    "                if self.repaired_head != None:\n",
    "                    proximal_term = 0.\n",
    "                    for local_param, standart_param in zip(self.model.head.parameters(), self.repaired_head.parameters()):\n",
    "                        proximal_term += torch.sum(torch.square(local_param - standart_param))\n",
    "                    loss += self.lamda * (self.mu / 2) * proximal_term\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        \n",
    "        self.lamda = (math.cos(r * math.pi / self.global_rounds) + 1) / 2\n",
    "\n",
    "    # Set the repaired global head to the local model.\n",
    "    def set_local_repaired_head(self, repaired_head): \n",
    "        if self.repaired_head == None:\n",
    "            self.repaired_head = copy.deepcopy(self.model.head)\n",
    "        \n",
    "        self.model.head.load_state_dict(repaired_head.state_dict())\n",
    "        self.repaired_head.load_state_dict(repaired_head.state_dict())\n",
    "\n",
    "    def get_local_repaired_head(self, flag=True):\n",
    "        # Create the prototype training set.\n",
    "        self.prototypes = self.get_local_prototypes(self.model)\n",
    "        \n",
    "        prototype_inputs = []\n",
    "        prototype_labels = []\n",
    "        for i, prototype in enumerate(self.prototypes):\n",
    "            if self.sample_per_class[i] != 0 :\n",
    "                prototype_inputs.append(prototype.tolist())\n",
    "                prototype_labels.append(i)\n",
    "        \n",
    "        prototype_inputs = torch.tensor(prototype_inputs).to(self.device)\n",
    "        prototype_labels = torch.tensor(prototype_labels).to(self.device)\n",
    "\n",
    "        prototype_inputs, prototype_labels = dataset_repeat(prototype_inputs, prototype_labels, batch_size=32)\n",
    "        \n",
    "        prototype_dataset = CustomDataset(prototype_inputs, prototype_labels)\n",
    "        prototype_dataloader = DataLoader(prototype_dataset, batch_size=32, drop_last=False, shuffle=True)\n",
    "        \n",
    "        # This step is performed after the global model is sent to the local model, so repaired_head_temp is initialized as the global head.\n",
    "        repaired_head_temp = copy.deepcopy(self.model.head)\n",
    "        optimizer = torch.optim.SGD(repaired_head_temp.parameters(), lr=self.ft_learning_rate)\n",
    "        \n",
    "        # Fine-tune the global head.\n",
    "        repaired_head_temp.train()\n",
    "        for step in range(self.revise_steps):\n",
    "            for i, (x, y) in enumerate(prototype_dataloader):\n",
    "                if type(x) == type([]):\n",
    "                    x[0] = x[0].to(self.device)\n",
    "                else:\n",
    "                    x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "            \n",
    "                optimizer.zero_grad()\n",
    "                output = repaired_head_temp(x)\n",
    "                loss   = self.loss(output, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        return repaired_head_temp\n",
    "    \n",
    "    # Extract prototypes.\n",
    "    def get_local_prototypes(self, model):\n",
    "        features = torch.tensor([torch.zeros_like(self.feature_shape).tolist() for _ in range(self.num_classes)]).to(self.device)\n",
    "        \n",
    "        trainloader = self.load_train_data(batch_size=300)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i , (x, y) in enumerate(trainloader):\n",
    "                if type(x) == type([]):\n",
    "                    x[0] = x[0].to(self.device)\n",
    "                else:\n",
    "                    x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                \n",
    "                output_base = model.base(x)\n",
    "                for output_feature, yy in zip(output_base.detach(), y):\n",
    "                    features[yy.item()] += output_feature\n",
    "        \n",
    "        \n",
    "        prototypes = torch.zeros_like(features).to(self.device)\n",
    "        for i, (prototype, num) in enumerate(zip(features, self.sample_per_class)):\n",
    "            if num == 0:\n",
    "                prototypes[i] = torch.zeros_like(prototype) \n",
    "            else:\n",
    "                prototypes[i] = prototype / num\n",
    "\n",
    "        return prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = 87915\n",
    "max_len=200\n",
    "emb_dim=64\n",
    "\n",
    "def run(args):\n",
    "    time_list = []\n",
    "    \n",
    "    for i in range(args.prev, args.times):\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"\\n============= Running time: {i}th =============\")\n",
    "        print(\"Creating server and clients ...\")\n",
    "        \n",
    "        if args.dataset[:8] == \"cifar100\":\n",
    "            args.num_classes = 100\n",
    "        elif args.dataset[:9] == \"pathmnist\":\n",
    "            args.num_classes = 9\n",
    "        elif args.dataset[:11] == \"organamnist\":\n",
    "            args.num_classes = 11\n",
    "        elif args.dataset[:6] == \"agnews\":\n",
    "            args.num_classes = 4\n",
    "            vocab_size = 87915\n",
    "        elif args.dataset[:9] == \"sogounews\":\n",
    "            args.num_classes = 5\n",
    "            vocab_size = 145835\n",
    "        else:\n",
    "            args.num_classes = 10\n",
    "        \n",
    "        # Generate args.model\n",
    "        model_str = args.model\n",
    "        if model_str == \"cnn\":\n",
    "            if args.dataset == \"organamnist\" or args.dataset == \"fmnist\":\n",
    "                args.model = CNN(in_features=1, num_classes=args.num_classes, dim=1024).to(args.device)\n",
    "                \n",
    "            elif args.dataset == \"pathmnist\":\n",
    "                args.model = CNN(in_features=3, num_classes=args.num_classes, dim=1024).to(args.device)\n",
    "\n",
    "            elif args.dataset == \"cifar10\":\n",
    "                args.model = CNN(in_features=3, num_classes=args.num_classes, dim=1600).to(args.device)\n",
    "                \n",
    "            elif args.dataset == \"cifar100\":\n",
    "                args.model = CNN(in_features=3, num_classes=args.num_classes, dim=1600, dim1=1024).to(args.device)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        head = copy.deepcopy(args.model.fc)\n",
    "        args.model.fc = nn.Identity()\n",
    "        args.model = BaseHeadSplit(args.model, head)\n",
    "\n",
    "        for key, value in vars(args).items():\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "        if args.algorithm == \"FedMR\":\n",
    "            server = FedMR(args, i)\n",
    "        elif args.algorithm == \"FedAvg\":\n",
    "            server = FedAvg(args, i)\n",
    "        elif args.algorithm == \"SCAFFOLD\":\n",
    "            server = SCAFFOLD(args, i)\n",
    "        elif args.algorithm == \"FedNTD\":\n",
    "            server = FedNTD(args, i)\n",
    "        elif args.algorithm == \"FedGEN\":\n",
    "            server = FedGEN(args, i)\n",
    "        elif args.algorithm == \"FedProto\":\n",
    "            server = FedProto(args, i)\n",
    "        elif args.algorithm == \"FedDyn\":\n",
    "            server = FedDyn(args, i)\n",
    "        elif args.algorithm == \"MOON\":\n",
    "            server = MOON(args, i)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        start = time.time()\n",
    "        server.train()\n",
    "        time_list.append(time.time()-start)\n",
    "        \n",
    "    print(f\"\\nAverage time cost: {round(np.average(time_list), 2)}s.\")\n",
    "    print(\"All done!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class config():\n",
    "    def __init__(self):\n",
    "        self.algorithm = \"FedMR\"\n",
    "        self.task = \"-\"\n",
    "        self.model = \"cnn\"\n",
    "        self.dataset = \"cifar10\"\n",
    "        self.batch_size = 32\n",
    "        self.local_learning_rate = 0.01\n",
    "        self.global_rounds = 150\n",
    "        self.local_steps = 5\n",
    "        self.join_ratio = 0.1\n",
    "        self.num_clients = 50                                                                        \n",
    "        self.num_classes = 10\n",
    "\n",
    "        self.revise_steps = 100\n",
    "        self.mu = 0.01\n",
    "        self.ft_learning_rate = 0.01\n",
    "        \n",
    "        self.head = None\n",
    "        self.device = \"cuda\"\n",
    "        self.device_id = \"0\"\n",
    "        \n",
    "        self.random_join_ratio = False\n",
    "        self.prev = 0\n",
    "        self.times = 8\n",
    "        self.eval_gap = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    total_start = time.time()\n",
    "    \n",
    "    args = config()\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.device_id\n",
    "    # torch.cuda.set_device(int(args.device_id))\n",
    "    \n",
    "    if args.device == \"cuda\" and not torch.cuda.is_available():\n",
    "        print(\"\\ncuda is not avaiable.\\n\")\n",
    "        args.device = \"cpu\" \n",
    "    torch.cuda.empty_cache()\n",
    "    run(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
